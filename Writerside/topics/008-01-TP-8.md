Parfait. C'est l'heure du grand final d'assemblage. Nous allons prendre toutes les pièces que nous avons construites et
les faire fonctionner ensemble sans effort grâce à Docker Compose.

---

# TP 8 : La Symphonie Complète - Orchestration de l'Écosystème avec Docker Compose

### Objectifs Pédagogiques

À la fin de ce TP, vous serez capable de :

* Créer un fichier `docker-compose.yml` complet pour une architecture microservices.
* Définir et configurer plusieurs services (Config Server, Eureka, services métier, Gateway).
* Gérer les dépendances de démarrage entre les services avec `depends_on`.
* Utiliser la résolution de noms de Docker Compose pour la communication inter-conteneurs.
* Lancer et arrêter l'ensemble de l'écosystème avec une seule commande.
* (Optionnel) Remplacer la base de données H2 par un service PostgreSQL dans Docker Compose.

### Introduction : Mettre l'orchestre en musique

Nous avons passé beaucoup de temps à fabriquer chaque instrument de notre orchestre : le violon (`product-service`), le
violoncelle (`order-service`), le piano (`config-server`), le métronome (`eureka-server`) et la partition du chef (
`api-gateway`). Chaque instrument est parfaitement accordé et emballé dans sa boîte (son image Docker).

Mais jusqu'à présent, pour jouer un morceau, nous devions sortir chaque instrument de sa boîte un par un, dans le bon
ordre, et les placer sur la scène. C'était fastidieux.

Avec ce TP, nous allons écrire la "partition" ultime : le fichier **`docker-compose.yml`**. Ce fichier va décrire
l'ensemble de notre orchestre, qui doit jouer, où il doit se placer, et qui doit attendre qui. Une fois cette partition
écrite, une seule commande du chef d'orchestre (`docker-compose up`) suffira pour que la symphonie commence. C'est l'
étape qui rend notre application facilement partageable et exécutable par n'importe quel développeur.

### Étape 1 : Préparation du projet global

Pour une meilleure organisation, nous allons créer un fichier `docker-compose.yml` à la racine d'un projet "parent" qui
englobe tous nos microservices.

<procedure>
<p>1. Sur votre système de fichiers, créez un dossier parent, par exemple <code>gestbook-microservices</code>.</p>
<p>2. Déplacez tous les dossiers de vos projets de microservices (`product-service`, `order-service`, `eureka-server`, `config-server`, `api-gateway`) et le dossier de configuration (`gestbook-config-repo`) à l'intérieur de ce dossier parent.</p>
<p>Votre structure devrait ressembler à ceci :</p>

```
gestbook-microservices/
├── api-gateway/
├── config-server/
├── eureka-server/
├── order-service/
├── product-service/
├── gestbook-config-repo/
└── docker-compose.yml   <-- Nous allons créer ce fichier
```

</procedure>

### Étape 2 : Construction de toutes les images Docker

Avant de pouvoir orchestrer nos services, nous devons nous assurer que toutes nos images Docker sont à jour.

<procedure>
<p>Pour chaque service (`config-server`, `eureka-server`, `product-service`, `order-service`, `api-gateway`), naviguez dans son dossier et exécutez les commandes :</p>
<command>
# Exemple pour product-service
cd product-service
mvn clean package
docker build -t product-service:latest .
cd ..
</command>
<p>Répétez cette opération pour tous les services, en veillant à bien nommer chaque image (ex: `api-gateway:latest`, `config-server:latest`, etc.). L'utilisation du tag `latest` est courante en développement.</p>
</procedure>

### Étape 3 : Écriture du fichier `docker-compose.yml`

À la racine de votre dossier `gestbook-microservices`, créez le fichier `docker-compose.yml` et ajoutez-y le contenu
suivant. Nous allons le construire bloc par bloc.

```yaml
# Version de la syntaxe Docker Compose
version: '3.8'

# Définition de tous nos services (conteneurs)
services:

  # 1. Le Config Server : il doit démarrer en premier
  config-server:
    image: config-server:latest # L'image que nous avons construite
    ports:
      - "8888:8888" # Expose son port sur la machine hôte
    volumes:
      # On monte le dossier de configuration local directement dans le conteneur.
      # C'est très pratique en développement pour voir les changements
      # sans avoir à reconstruire l'image du config-server.
      - ./gestbook-config-repo:/config-repo
    environment:
      # On surcharge l'URI Git pour qu'elle pointe vers le volume monté.
      - SPRING_CLOUD_CONFIG_SERVER_GIT_URI=file:///config-repo
      - EUREKA_CLIENT_SERVICEURL_DEFAULTZONE=http://eureka-server:8761/eureka
    healthcheck:
      # Vérifie que le service est réellement prêt
      test: [ "CMD", "curl", "-f", "http://localhost:8888/actuator/health" ]
      interval: 30s
      timeout: 10s
      retries: 5

  # 2. Le Serveur Eureka : il dépend du Config Server pour sa configuration
  eureka-server:
    image: eureka-server:latest
    ports:
      - "8761:8761"
    environment:
      # On lui dit où trouver le Config Server dans le réseau Docker
      - SPRING_CLOUD_CONFIG_URI=http://config-server:8888
    depends_on:
      config-server:
        condition: service_healthy # Attend que le healthcheck du config-server passe

  # 3. Le Product Service : dépend d'Eureka et du Config Server
  product-service:
    image: product-service:latest
    ports:
      - "8081:8081"
    environment:
      - SPRING_CLOUD_CONFIG_URI=http://config-server:8888
    depends_on:
      eureka-server:
        condition: service_started # On peut être moins strict ici
      config-server:
        condition: service_healthy

  # 4. Le Order Service : idem
  order-service:
    image: order-service:latest
    ports:
      - "8082:8082"
    environment:
      - SPRING_CLOUD_CONFIG_URI=http://config-server:8888
    depends_on:
      product-service: # Il dépend fonctionnellement de product-service
        condition: service_started
      eureka-server:
        condition: service_started
      config-server:
        condition: service_healthy

  # 5. L'API Gateway : la porte d'entrée
  api-gateway:
    image: api-gateway:latest
    ports:
      - "8080:8080" # Le seul port réellement nécessaire pour l'utilisateur final
    environment:
      - SPRING_CLOUD_CONFIG_URI=http://config-server:8888
    depends_on:
      eureka-server:
        condition: service_started
      config-server:
        condition: service_healthy

```

<warning>
<b>Dépendances et Healthchecks</b>
<p>
Notez l'utilisation de <code>depends_on</code> avec <code>condition: service_healthy</code> pour le <code>config-server</code>. C'est une manière plus robuste d'attendre qu'un service soit réellement prêt. Pour que cela fonctionne, il faut que le <code>config-server</code> expose un endpoint <code>/actuator/health</code> (ce qui est le cas si on a la dépendance Actuator).
</p>
<p>
Nous avons aussi ajusté les URLs pour utiliser les noms de service Docker (ex: <code>http://config-server:8888</code>). C'est la magie de la résolution de nom interne de Docker Compose !
</p>
</warning>

### Étape 4 : Lancement et validation de la symphonie

<procedure>
<p>1. Assurez-vous qu'aucun des conteneurs précédents ne tourne (`docker stop $(docker ps -aq)` peut être utile pour tout arrêter).</p>
<p>2. Ouvrez un terminal à la racine de votre projet `gestbook-microservices`.</p>
<p>3. Lancez la commande magique :</p>
<command>
docker-compose up
</command>
<p>Vous allez voir un flot de logs colorés, chaque couleur correspondant à un service. Docker Compose va démarrer les conteneurs dans l'ordre défini par `depends_on`.</p>
<p>Attendez que les logs se stabilisent et que tous les services aient démarré et se soient enregistrés auprès d'Eureka.</p>
<p>4. <b>Validation :</b></p>
<ul>
    <li>Ouvrez <a href="http://localhost:8761/">http://localhost:8761/</a> pour voir le dashboard Eureka. Tous vos services (<code>CONFIG-SERVER</code>, <code>PRODUCT-SERVICE</code>, <code>ORDER-SERVICE</code>, <code>API-GATEWAY</code>) devraient y être listés.</li>
    <li>Ouvrez <a href="http://localhost:8888/product-service/default">http://localhost:8888/product-service/default</a> pour vérifier que le Config Server est accessible et sert la bonne configuration.</li>
    <li>Utilisez votre client HTTP pour faire un appel de bout en bout, <b>en passant uniquement par la Gateway</b> :</li>
</ul>

```http request
### End-to-End Test with Docker Compose
POST http://localhost:8080/api/orders
Content-Type: application/json

{
"productId": 2,
"quantity": 1
}
```

<p>Si vous recevez une réponse `201 Created`, c'est un succès total ! Votre requête a traversé la Gateway, qui a contacté `order-service`, qui a lui-même contacté `product-service`, le tout orchestré par Docker Compose et dynamiquement lié par Eureka et le Config Server.</p>
<p>5. Pour tout arrêter proprement, ouvrez un autre terminal dans le même dossier et tapez :</p>
<command>
docker-compose down
</command>
<p>Tous les conteneurs et le réseau seront nettoyés.</p>
</procedure>

---

### Exercice 11 (Optionnel) : Utiliser une "vraie" base de données

**Contexte :** La base de données en mémoire H2 est pratique, mais elle perd toutes ses données à chaque redémarrage.
Remplaçons-la par un service PostgreSQL dans notre `docker-compose.yml`.

**Votre mission :**

1. Dans `docker-compose.yml`, ajoutez un nouveau service nommé `postgres-db`. Utilisez une image officielle comme
   `postgres:13`. Vous devrez configurer des variables d'environnement pour le mot de passe, l'utilisateur et le nom de
   la base de données (ex: `POSTGRES_PASSWORD`, `POSTGRES_USER`, `POSTGRES_DB`).
2. Dans `docker-compose.yml`, faites en sorte que `product-service` et `order-service` dépendent de `postgres-db` (
   `depends_on`).
3. Dans le dépôt `gestbook-config-repo`, modifiez les fichiers `product-service.properties` et
   `order-service.properties`. Remplacez la configuration H2 par la configuration de la source de données PostgreSQL.
   L'URL JDBC ressemblera à `jdbc:postgresql://postgres-db:5432/gestbook_db`. Le `driver-class-name` sera
   `org.postgresql.Driver`. Utilisez les variables d'environnement pour le nom d'utilisateur et le mot de passe.
4. Dans les `pom.xml` de `product-service` et `order-service`, remplacez la dépendance `h2` par celle du driver
   PostgreSQL : `postgresql`.
5. Reconstruisez les images de `product-service` et `order-service`.
6. Lancez `docker-compose up` et vérifiez que tout fonctionne. Créez un produit (il faudra ajouter un endpoint `POST`
   dans `ProductController`). Arrêtez et redémarrez tout avec `docker-compose down` puis `up`. Le produit que vous avez
   créé est-il toujours là ? (Indice : il vous faudra utiliser un `volume` sur le service `postgres-db` pour persister
   les données).

#### Correction exercice 11 {collapsible='true'}

1. **Ajout du service PostgreSQL dans `docker-compose.yml`**:
   ```yaml
   services:
     # ... autres services
     postgres-db:
       image: postgres:13
       environment:
         - POSTGRES_USER=gestbook
         - POSTGRES_PASSWORD=password
         - POSTGRES_DB=gestbook_db
       ports:
         - "5432:5432" # Utile pour se connecter avec un client DB externe
       volumes:
         # Ce volume persistera les données de la DB entre les 'down' et 'up'
         - postgres_data:/var/lib/postgresql/data

   # ...
   volumes:
     postgres_data: # Déclaration du volume nommé
   ```
2. **Mise à jour des dépendances de service**:
   ```yaml
   # Dans la définition de product-service et order-service
   depends_on:
     # ... autres dépendances
     postgres-db:
       condition: service_started
   ```
3. **Mise à jour de `product-service.properties` (idem pour `order-service`)**:
   ```properties
   # server.port=8081
   spring.datasource.url=jdbc:postgresql://postgres-db:5432/gestbook_db
   spring.datasource.username=gestbook
   spring.datasource.password=password
   spring.datasource.driver-class-name=org.postgresql.Driver
   # Permet à Hibernate de générer le schéma au démarrage
   spring.jpa.hibernate.ddl-auto=update
   ```
4. **Mise à jour des `pom.xml`**:
   ```xml
   <!-- Remplacer h2 par -->
   <dependency>
       <groupId>org.postgresql</groupId>
       <artifactId>postgresql</artifactId>
       <scope>runtime</scope>
   </dependency>
   ```
5. et 6. Après avoir reconstruit les images et lancé `docker-compose up`, les services se connecteront à la base de
   données PostgreSQL. Grâce au volume `postgres_data`, les données créées persisteront même après un
   `docker-compose down`.

---

### Auto-évaluation

1. **(QCM)** Quelle est la commande pour lancer un écosystème Docker Compose et voir les logs en direct ?
    * A) `docker-compose start`
    * B) `docker-compose up -d`
    * C) `docker-compose up`
    * D) `docker-compose logs`
2. **(Question ouverte)** Dans notre `docker-compose.yml`, `product-service` est configuré avec
   `SPRING_CLOUD_CONFIG_URI=http://config-server:8888`. Expliquez comment `product-service` peut résoudre le nom d'hôte
   `config-server`.
3. **(QCM)** La directive `depends_on` dans Docker Compose :
    * A) Garantit que le service dépendant est pleinement opérationnel avant de lancer le suivant.
    * B) Contrôle uniquement l'ordre de démarrage des conteneurs.
    * C) Crée un lien réseau direct entre les conteneurs.
    * D) N'est plus supportée dans la version 3.
4. **(Question ouverte)** Pourquoi avons-nous monté le dossier `gestbook-config-repo` en tant que `volume` pour le
   `config-server` dans notre `docker-compose.yml` ? Quel est l'avantage en développement ?
5. **(QCM)** Pour arrêter et supprimer proprement tous les services lancés par Docker Compose, on utilise :
    * A) `docker stop all`
    * B) `docker-compose kill`
    * C) `docker-compose stop`
    * D) `docker-compose down`

---

### Conclusion

C'est un moment décisif. Vous avez assemblé et orchestré une architecture microservices complète, du serveur de
configuration jusqu'à la passerelle API, avec une seule commande. Vous avez transformé un processus de démarrage
complexe et manuel en une opération simple, fiable et reproductible.

**Docker Compose** est désormais un outil essentiel dans votre boîte à outils de développeur. Il vous permet de :

* Définir votre environnement de développement de manière déclarative.
* Simplifier la collaboration au sein de votre équipe.
* Simuler de manière réaliste un environnement de production multi-conteneurs.

Notre architecture est maintenant fonctionnelle, dynamique, configurable, résiliente et facile à lancer. Nous avons
construit des fondations solides. Il est temps maintenant de s'attaquer à des sujets plus avancés qui rendent ces
architectures prêtes pour la production, comme la **sécurité**, le **monitoring** et les **logs centralisés**.
L'aventure continue 